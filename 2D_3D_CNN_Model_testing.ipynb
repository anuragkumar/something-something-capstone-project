{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook implements 2D CNN (VGG16) as feature extractor\n",
    "# and implements 3D CNN for final prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code is written to reuse as much memory as possible to\n",
    "# minimize the memory usage as the amount of data (extracted images)\n",
    "# is large and I have only 16 GB of RAM space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My system comfiguration:\n",
    "# 16 GB RAM\n",
    "# 1 TB HDD\n",
    "# 256 GB SSD\n",
    "# NVIDIA GTX 1070 8 GB GPU RAM\n",
    "# I7 8th GEN Intel CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Light\\anaconda3\\envs\\dogs-vs-cats\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Light\\anaconda3\\envs\\dogs-vs-cats\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Light\\anaconda3\\envs\\dogs-vs-cats\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Light\\anaconda3\\envs\\dogs-vs-cats\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Light\\anaconda3\\envs\\dogs-vs-cats\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Light\\anaconda3\\envs\\dogs-vs-cats\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Light\\anaconda3\\envs\\dogs-vs-cats\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Light\\anaconda3\\envs\\dogs-vs-cats\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Light\\anaconda3\\envs\\dogs-vs-cats\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Light\\anaconda3\\envs\\dogs-vs-cats\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Light\\anaconda3\\envs\\dogs-vs-cats\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Light\\anaconda3\\envs\\dogs-vs-cats\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# for loading images\n",
    "import glob\n",
    "\n",
    "# for image array processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# for maintaing system path\n",
    "import os\n",
    "\n",
    "# for processing images\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# encoding labels catogories\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# multi class encoding\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# pretrained model\n",
    "from keras.applications import vgg16\n",
    "\n",
    "# Our 3D model\n",
    "from keras.models import Model\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Dropout, BatchNormalization, InputLayer\n",
    "from keras.utils import to_categorical\n",
    "import h5py\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and validation directories\n",
    "train_dir = 'D:\\\\something-something-project\\\\train-images\\\\'\n",
    "validation_dir = 'D:\\\\something-something-project\\\\validation-images\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dropping_something', 'Holding_something', 'Moving_something', 'Picking_something', 'Poking_something', 'Pouring_something', 'Putting_something', 'Showing_something', 'Tearing_something']\n",
      "['Dropping_something', 'Holding_something', 'Moving_something', 'Picking_something', 'Poking_something', 'Pouring_something', 'Putting_something', 'Showing_something', 'Tearing_something']\n"
     ]
    }
   ],
   "source": [
    "# listing images directory for train and validation\n",
    "train_files = os.listdir(train_dir)\n",
    "print (train_files)\n",
    "\n",
    "validation_files = os.listdir(validation_dir)\n",
    "print (validation_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D:\\\\something-something-project\\\\train-images\\\\Dropping_something', 'D:\\\\something-something-project\\\\train-images\\\\Holding_something', 'D:\\\\something-something-project\\\\train-images\\\\Moving_something', 'D:\\\\something-something-project\\\\train-images\\\\Picking_something', 'D:\\\\something-something-project\\\\train-images\\\\Poking_something', 'D:\\\\something-something-project\\\\train-images\\\\Pouring_something', 'D:\\\\something-something-project\\\\train-images\\\\Putting_something', 'D:\\\\something-something-project\\\\train-images\\\\Showing_something', 'D:\\\\something-something-project\\\\train-images\\\\Tearing_something']\n",
      "['D:\\\\something-something-project\\\\validation-images\\\\Dropping_something', 'D:\\\\something-something-project\\\\validation-images\\\\Holding_something', 'D:\\\\something-something-project\\\\validation-images\\\\Moving_something', 'D:\\\\something-something-project\\\\validation-images\\\\Picking_something', 'D:\\\\something-something-project\\\\validation-images\\\\Poking_something', 'D:\\\\something-something-project\\\\validation-images\\\\Pouring_something', 'D:\\\\something-something-project\\\\validation-images\\\\Putting_something', 'D:\\\\something-something-project\\\\validation-images\\\\Showing_something', 'D:\\\\something-something-project\\\\validation-images\\\\Tearing_something']\n"
     ]
    }
   ],
   "source": [
    "# generating the full system path\n",
    "train_files_dir = []\n",
    "validation_files_dir = []\n",
    "\n",
    "for f in train_files:\n",
    "    if os.path.join(train_dir, f):\n",
    "        train_files_dir.append(os.path.join(train_dir, f))\n",
    "        \n",
    "for f in validation_files:\n",
    "    if os.path.join(validation_dir, f):\n",
    "        validation_files_dir.append(os.path.join(validation_dir, f))\n",
    "        \n",
    "print (train_files_dir)\n",
    "print (validation_files_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del train_files\n",
    "# del validation_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data\n",
      "D:\\something-something-project\\train-images\\Dropping_something 15941\n",
      "D:\\something-something-project\\train-images\\Holding_something 25433\n",
      "D:\\something-something-project\\train-images\\Moving_something 56940\n",
      "D:\\something-something-project\\train-images\\Picking_something 3841\n",
      "D:\\something-something-project\\train-images\\Poking_something 14179\n",
      "D:\\something-something-project\\train-images\\Pouring_something 7280\n",
      "D:\\something-something-project\\train-images\\Putting_something 64208\n",
      "D:\\something-something-project\\train-images\\Showing_something 15682\n",
      "D:\\something-something-project\\train-images\\Tearing_something 11816\n"
     ]
    }
   ],
   "source": [
    "# printing number of images in each directories\n",
    "print (\"Training Data\")\n",
    "for d in train_files_dir:\n",
    "    print (d, len(os.listdir(d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Data\n",
      "D:\\something-something-project\\validation-images\\Dropping_something 3108\n",
      "D:\\something-something-project\\validation-images\\Holding_something 4148\n",
      "D:\\something-something-project\\validation-images\\Moving_something 7463\n",
      "D:\\something-something-project\\validation-images\\Picking_something 774\n",
      "D:\\something-something-project\\validation-images\\Poking_something 1618\n",
      "D:\\something-something-project\\validation-images\\Pouring_something 2023\n",
      "D:\\something-something-project\\validation-images\\Putting_something 7867\n",
      "D:\\something-something-project\\validation-images\\Showing_something 2627\n",
      "D:\\something-something-project\\validation-images\\Tearing_something 3851\n"
     ]
    }
   ],
   "source": [
    "# printing number of images in each directories\n",
    "print (\"Validation Data\")\n",
    "for d in validation_files_dir:\n",
    "    print (d, len(os.listdir(d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory:  D:\\something-something-project\\train-images\\Dropping_something\n",
      "Directory:  D:\\something-something-project\\train-images\\Holding_something\n",
      "Directory:  D:\\something-something-project\\train-images\\Moving_something\n",
      "Directory:  D:\\something-something-project\\train-images\\Picking_something\n",
      "Directory:  D:\\something-something-project\\train-images\\Poking_something\n",
      "Directory:  D:\\something-something-project\\train-images\\Pouring_something\n",
      "Directory:  D:\\something-something-project\\train-images\\Putting_something\n",
      "Directory:  D:\\something-something-project\\train-images\\Showing_something\n",
      "Directory:  D:\\something-something-project\\train-images\\Tearing_something\n"
     ]
    }
   ],
   "source": [
    "# loading training data\n",
    "train_data = []\n",
    "train_labels = []\n",
    "for d in train_files_dir:\n",
    "    print ('Directory: ', d)\n",
    "    # commenting out so that one can read all the images, I have less RAM\n",
    "    count = 0\n",
    "    files = glob.glob(d + \"/*.jpg\")\n",
    "    imgs = []\n",
    "    for img in files:\n",
    "        # print (img)\n",
    "        if count == 1000:\n",
    "            break\n",
    "        if not os.path.isfile(img):\n",
    "            continue\n",
    "        imgs.append(cv2.imread(img))\n",
    "        train_labels.append(d.split(\"D:\\\\something-something-project\\\\train-images\\\\\")[1])\n",
    "        count += 1\n",
    "    train_data = train_data + imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory:  D:\\something-something-project\\validation-images\\Dropping_something\n",
      "Directory:  D:\\something-something-project\\validation-images\\Holding_something\n",
      "Directory:  D:\\something-something-project\\validation-images\\Moving_something\n",
      "Directory:  D:\\something-something-project\\validation-images\\Picking_something\n",
      "Directory:  D:\\something-something-project\\validation-images\\Poking_something\n",
      "Directory:  D:\\something-something-project\\validation-images\\Pouring_something\n",
      "Directory:  D:\\something-something-project\\validation-images\\Putting_something\n",
      "Directory:  D:\\something-something-project\\validation-images\\Showing_something\n",
      "Directory:  D:\\something-something-project\\validation-images\\Tearing_something\n"
     ]
    }
   ],
   "source": [
    "# loading validation data\n",
    "validation_data = []\n",
    "validation_labels = []\n",
    "for d in validation_files_dir:\n",
    "    print ('Directory: ', d)\n",
    "    count = 0\n",
    "    files = glob.glob(d + \"/*.jpg\")\n",
    "    imgs = []\n",
    "    for img in files:\n",
    "        if count == 500:\n",
    "            break\n",
    "        if not os.path.isfile(img):\n",
    "            continue\n",
    "        imgs.append(cv2.imread(img))\n",
    "        validation_labels.append(d.split(\"D:\\\\something-something-project\\\\validation-images\\\\\")[1])\n",
    "        count += 1\n",
    "    validation_data = validation_data + imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data:  9000 \tTrain Labels:  9000\n",
      "Validation Data:  4500 \tValidation Labels:  4500\n"
     ]
    }
   ],
   "source": [
    "print (\"Train Data: \", len(train_data), \"\\tTrain Labels: \", len(train_labels))\n",
    "print (\"Validation Data: \", len(validation_data), \"\\tValidation Labels: \", len(validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data (there are some corrupted files, so use the next column)\n",
    "IMG_DIM = (84, 84)\n",
    "\n",
    "train_imgs = [img_to_array(cv2.resize(img, IMG_DIM)) for img in train_data]\n",
    "train_imgs = np.array(train_imgs)\n",
    "\n",
    "validation_imgs = [img_to_array(cv2.resize(img, IMG_DIM)) for img in validation_data]\n",
    "validation_imgs = np.array(validation_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training Data\n",
    "# # since there are few corrupted images, we need to remove that label as well\n",
    "# IMG_DIM = (84, 84)\n",
    "# train_imgs = []\n",
    "# validation_imgs = []\n",
    "\n",
    "# i = 0\n",
    "\n",
    "# while i < len(train_data):\n",
    "#     try:\n",
    "#         train_imgs.append(img_to_array(cv2.resize(img, IMG_DIM)))\n",
    "#         i += 1\n",
    "#     except Exception as e:\n",
    "#         print ('Exception found: ', e)\n",
    "#         # delete from label as well\n",
    "#         del train_labels[i]\n",
    "#         i += 1\n",
    "#         continue\n",
    "        \n",
    "# train_imgs = np.array(train_imgs)\n",
    "        \n",
    "# i = 0\n",
    "\n",
    "# while i < len(validation_data):\n",
    "#     try:\n",
    "#         validation_imgs.append(img_to_array(cv2.resize(img, IMG_DIM)))\n",
    "#         i += 1\n",
    "#     except Exception as e:\n",
    "#         print ('Exception found: ', e)\n",
    "#         # delete from label as well\n",
    "#         del validation_labels[i]\n",
    "#         i += 1\n",
    "#         continue\n",
    "        \n",
    "# validation_imgs = np.array(validation_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape: (9000, 84, 84, 3) \tValidation dataset shape: (4500, 84, 84, 3)\n"
     ]
    }
   ],
   "source": [
    "print('Train dataset shape:', train_imgs.shape, '\\tValidation dataset shape:', validation_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84, 84, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=84x84 at 0x21E2C0C0048>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_imgs_scaled = train_imgs.astype('float32')\n",
    "validation_imgs_scaled  = validation_imgs.astype('float32')\n",
    "train_imgs_scaled /= 255\n",
    "validation_imgs_scaled /= 255\n",
    "\n",
    "print(train_imgs[0].shape)\n",
    "array_to_img(train_imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "batch_size = 30\n",
    "num_classes = 9\n",
    "epochs = 30\n",
    "input_shape = (84, 84, 84, 3)\n",
    "\n",
    "# one hot encoding for training and validation\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_integer_encoded = label_encoder.fit_transform(train_labels)\n",
    "validation_labels_integer_encoded = label_encoder.fit_transform(validation_labels)\n",
    "\n",
    "# print(train_labels_integer_encoded)\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "train_labels_integer_encoded = train_labels_integer_encoded.reshape(len(train_labels_integer_encoded), 1)\n",
    "train_label_enc = onehot_encoder.fit_transform(train_labels_integer_encoded)\n",
    "\n",
    "validation_labels_integer_encoded = validation_labels_integer_encoded.reshape(len(validation_labels_integer_encoded), 1)\n",
    "validation_label_enc = onehot_encoder.fit_transform(validation_labels_integer_encoded)\n",
    "\n",
    "# print(train_labels[1495:1505], train_labels_enc[1495:1505])\n",
    "\n",
    "# # invert first example\n",
    "# inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])\n",
    "# print(inverted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`input_shape` must be a tuple of three integers.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-6df73ce6d301>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m vgg = vgg16.VGG16(include_top=False, weights='imagenet', \n\u001b[1;32m----> 4\u001b[1;33m                                      input_shape=input_shape)\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dogs-vs-cats\\lib\\site-packages\\keras\\applications\\__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'models'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'utils'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbase_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dogs-vs-cats\\lib\\site-packages\\keras\\applications\\vgg16.py\u001b[0m in \u001b[0;36mVGG16\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mkeras_modules_injection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mvgg16\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVGG16\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dogs-vs-cats\\lib\\site-packages\\keras_applications\\vgg16.py\u001b[0m in \u001b[0;36mVGG16\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[0;32m     97\u001b[0m                                       \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_data_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                                       \u001b[0mrequire_flatten\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m                                       weights=weights)\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dogs-vs-cats\\lib\\site-packages\\keras_applications\\imagenet_utils.py\u001b[0m in \u001b[0;36m_obtain_input_shape\u001b[1;34m(input_shape, default_size, min_size, data_format, require_flatten, weights)\u001b[0m\n\u001b[0;32m    311\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m                     raise ValueError(\n\u001b[1;32m--> 313\u001b[1;33m                         '`input_shape` must be a tuple of three integers.')\n\u001b[0m\u001b[0;32m    314\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m3\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'imagenet'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m                     raise ValueError('The input must have 3 channels; got '\n",
      "\u001b[1;31mValueError\u001b[0m: `input_shape` must be a tuple of three integers."
     ]
    }
   ],
   "source": [
    "# using pretrained VGG16 model\n",
    "\n",
    "vgg = vgg16.VGG16(include_top=False, weights='imagenet', \n",
    "                                     input_shape=input_shape)\n",
    "\n",
    "output = vgg.layers[-1].output\n",
    "output = keras.layers.Flatten()(output)\n",
    "vgg_model = Model(vgg.input, output)\n",
    "\n",
    "vgg_model.trainable = False\n",
    "for layer in vgg_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "pd.set_option('max_colwidth', -1)\n",
    "layers = [(layer, layer.name, layer.trainable) for layer in vgg_model.layers]\n",
    "pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Light\\anaconda3\\envs\\dogs-vs-cats\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "(1, 2, 2, 512)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21e2c04ae10>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bottleneck_feature_example = vgg.predict(train_imgs_scaled[0:1])\n",
    "print(bottleneck_feature_example.shape)\n",
    "plt.imshow(bottleneck_feature_example[0][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Bottleneck Features: (9000, 2048) \tValidation Bottleneck Features: (4500, 2048)\n"
     ]
    }
   ],
   "source": [
    "# getting the output format of VGG16 to make it sync with our output layer\n",
    "\n",
    "def get_bottleneck_features(model, input_imgs):\n",
    "    features = model.predict(input_imgs, verbose=0)\n",
    "    return features\n",
    "    \n",
    "train_features_vgg = get_bottleneck_features(vgg_model, train_imgs_scaled)\n",
    "validation_features_vgg = get_bottleneck_features(vgg_model, validation_imgs_scaled)\n",
    "\n",
    "print('Train Bottleneck Features:', train_features_vgg.shape, \n",
    "      '\\tValidation Bottleneck Features:', validation_features_vgg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_6 (Conv3D)            (None, 82, 82, 82, 32)    2624      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 41, 41, 41, 32)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 41, 41, 41, 32)    128       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 41, 41, 41, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_7 (Conv3D)            (None, 39, 39, 39, 64)    55360     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 19, 19, 19, 64)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 19, 19, 19, 64)    256       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 19, 19, 19, 64)    0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 438976)            0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               112378112 \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 9)                 2313      \n",
      "=================================================================\n",
      "Total params: 112,504,585\n",
      "Trainable params: 112,504,393\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# designing our output layer\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "# model.add(vgg_model)\n",
    "# model.add(InputLayer(input_shape=(input_shape,)))\n",
    "# model.add(Dense(512, activation='relu', input_dim=input_shape))\n",
    "model.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=input_shape))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "model.add(BatchNormalization(center=True, scale=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "model.add(BatchNormalization(center=True, scale=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(9, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(lr=0.001),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "# # Fit data to model\n",
    "# history = model.fit(X_train, targets_train,\n",
    "#             batch_size=128,\n",
    "#             epochs=40,\n",
    "#             verbose=1,\n",
    "#             validation_split=0.3)\n",
    "\n",
    "\n",
    "\n",
    "# input_shape = vgg_model.output_shape[1]\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(InputLayer(input_shape=(input_shape,)))\n",
    "# model.add(Dense(512, activation='relu', input_dim=input_shape))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(512, activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(9, activation='softmax'))\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv3d_6_input to have 5 dimensions, but got array with shape (9000, 2048)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-c8afa55c9e4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m                     verbose=1)\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\dogs-vs-cats\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dogs-vs-cats\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dogs-vs-cats\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    133\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    136\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected conv3d_6_input to have 5 dimensions, but got array with shape (9000, 2048)"
     ]
    }
   ],
   "source": [
    "# running the model\n",
    "history = model.fit(x=train_features_vgg, y=train_label_enc,\n",
    "                    validation_data=(validation_features_vgg, validation_label_enc),\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dogs-vs-cats",
   "language": "python",
   "name": "dogs-vs-cats"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
