#!/usr/bin/env python
# coding: utf-8

# In[23]:

from config2 import config
import os
import cv2
import time
import numpy as np
import pandas as pd
from flask import Response
import random
import io
import base64
# from IPython.display import HTML

from tensorflow.keras.preprocessing.image import img_to_array, array_to_img
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.applications.resnet50 import preprocess_input
from tensorflow.keras.applications import imagenet_utils
from imutils.object_detection import non_max_suppression


class ObjectDetection:
    def __init__(self):
        self.val_data = pd.read_json(config['json_data_val'], orient="records")
        self.model = ResNet50(weights="imagenet")
        self.method = "fast"  # ["fast", "slow"]
        self.conf = "0.9"  # minimum probabilty to consider a classification/detection

    def selective_search(self, image, method="fast"):
        # initialize OpenCV's selective search implementation and set the input image
        ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()
        ss.setBaseImage(image)

        # check to see if we are using "fast" but "less accurate" version of selective search
        if method == "fast":
            ss.switchToSelectiveSearchFast()

        # otherwise we are using "slower" but "more accurate" version
        else:
            ss.switchToSelectiveSearchQuality()

        # run selective search on the input image
        rects = ss.process()

        # return the region proposal bounding boxes
        return rects

    def get_object_detected_images(self, selected_index):
        # this will go in a function
        selected_row = self.val_data.loc[self.val_data['id'] == selected_index]
        path_to_vid = os.path.join(config["data_folder"], str(selected_index) + ".webm")

        vs = cv2.VideoCapture(path_to_vid)
        (W, H) = (None, None)

        frame_rate = 12
        prev = 0

        flag = False
        image_frames = []

        while True:
            time_elapsed = time.time() - prev

            if time_elapsed <= 1. / frame_rate:
                break

            if flag:
                break

            flag = True

            prev = time.time()

            # read the next frame from the file
            (grabbed, frame) = vs.read()

            # if the frame was not grabbed, then we have reached the end
            # of the stream
            if not grabbed:
                print("breaking")
                break

            # if the frame dimensions are empty, grab them
            if W is None or H is None:
                (H, W) = frame.shape[:2]

            # clone the output frame, then convert it from BGR to RGB
            # ordering, resize the frame to a fixed 224x224, and then
            # perform mean subtraction
            output = frame.copy()
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            frame = cv2.resize(frame, (224, 224))

            print("performing selective search with '{}' method".format(self.method))
            rects = self.selective_search(frame, method=self.method)
            print("{} regions found by selective search".format(len(rects)))

            # initialize the list of region proposals that we'll be classifying
            # along with their associated bounding boxes
            proposals = []
            boxes = []

            # loop over the region proposal bounding box coordinates generated by
            # running selective search
            for (x, y, w, h) in rects:
                # if the width or height of the region is less than 10% of the
                # image width or height, ignore it (i.e., filter out small
                # objects that are likely false-positives)
                if w / float(W) < 0.1 or h / float(H) < 0.1:
                    continue

                # extract the region from the input image, convert it from BGR to
                # RGB channel ordering, and them resize it to 224x224 (the input
                # dimesnsion required by our pretrained CNN)
                roi = frame[y:y + h, x:x + w]
                roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)
                roi = cv2.resize(roi, (224, 224))

                # further processing by the ROI
                roi = img_to_array(roi)
                roi = preprocess_input(roi)

                # update our proposals and bounding boxes lists
                proposals.append(roi)
                boxes.append((x, y, w, h))

            # convert the proposals list into numpy array and show its dimensions
            proposals = np.array(proposals)
            print("Proposal shape: {}".format(proposals.shape))

            # classify each of the proposal ROIs using ResNet and then decode the
            # predictions
            print("Classifying proposals...")
            preds = self.model.predict(proposals)
            preds = imagenet_utils.decode_predictions(preds, top=1)

            # initialize a dictionary which maps class labels (keys) to any
            # bounding box associated with that label (values)
            labels = {}

            # loop over the predictions
            for (i, p) in enumerate(preds):
                # grab the prediction information for the current region proposal
                (imagenetID, label, prob) = p[0]

                # only if the label filters are not empty "and" the label does not
                # exist in the list, then ignore it

                # try to look for label which we are interested in, else find the label with highest probability
                #     if labelFilters is not None and label not in labelFilters:
                #         continue

                # filter out weak detections by ensuring the predicted probability
                # is greater than the minimum probability
                if prob >= float(self.conf):
                    # grab the bounding box associated with the prediction and
                    # convert the coordinates
                    (x, y, w, h) = boxes[i]
                    box = (x, y, x + w, y + h)

                    # grab the list of predictions for the label and add the
                    # bounding box + probability to the list
                    L = labels.get(label, [])
                    L.append((box, prob))
                    labels[label] = L

            for label in labels.keys():
                print("[INFO] showing results for '{}'".format(label))
                clone = frame.copy()
                # extract the bounding boxes and associated prediction
                # probabilities, then apply non-maxima suppression
                boxes = np.array([p[0] for p in labels[label]])
                proba = np.array([p[1] for p in labels[label]])
                boxes = non_max_suppression(boxes, proba)
                # loop over all bounding boxes that were kept after applying
                # non-maxima suppression
                print(proba)
                print(boxes)
                for (startX, startY, endX, endY), prob in zip(boxes, proba):
                    # draw the bounding box and label on the image
                    cv2.rectangle(clone, (startX, startY), (endX, endY),
                                  (0, 255, 0), 2)
                    y = startY - 10 if startY - 10 > 10 else startY + 10
                    cv2.putText(clone, label + " {0:.0%}".format(prob), (startX, y),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 2)

                image_frames.append(clone)
                # show the output after apply non-maxima suppression
                # cv2.imshow("After", clone)
                # cv2.waitKey(0)
            #     plt.imshow(clone)
            # plt.show(block=True)

        # res = []
        # for img in image_frames:
        #     fig = Figure()
        #     plt.imshow(array_to_img(img))
        #     plt.show()
        #     response =
        # plt.figure()
        # plt.plot(array_to_img(image_frames[0]))
        return image_frames


def main():
    print("hello world")
    obj_detection = ObjectDetection()
    res = obj_detection.get_object_detected_images(52838)
    print(res)


if __name__ == "__main__":
    main()
